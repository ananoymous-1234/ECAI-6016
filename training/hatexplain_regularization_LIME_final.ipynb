{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2921,"status":"ok","timestamp":1746008400394,"user":{"displayName":"Deedahwar Mazhar","userId":"00396218496300543878"},"user_tz":-60},"id":"5sDbkJLemS9h","outputId":"ae3c4676-ba17-4bbb-e243-56e3b6b2cd88"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n","Requirement already satisfied: lime in /usr/local/lib/python3.11/dist-packages (0.2.0.1)\n","Requirement already satisfied: hf_xet in /usr/local/lib/python3.11/dist-packages (1.1.0)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.1)\n","Requirement already satisfied: captum in /usr/local/lib/python3.11/dist-packages (0.8.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from lime) (3.10.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lime) (1.15.2)\n","Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.11/dist-packages (from lime) (1.6.1)\n","Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.11/dist-packages (from lime) (0.25.2)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n","Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.11/dist-packages (from captum) (2.6.0+cu124)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (3.4.2)\n","Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (11.2.1)\n","Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2.37.0)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2025.3.30)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (0.4)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->lime) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->lime) (3.6.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10->captum) (1.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (4.57.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.4.8)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10->captum) (3.0.2)\n"]}],"source":["!pip install transformers lime hf_xet datasets captum numpy"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"AW7XpS3PmfHt","executionInfo":{"status":"ok","timestamp":1746008409271,"user_tz":-60,"elapsed":8875,"user":{"displayName":"Deedahwar Mazhar","userId":"00396218496300543878"}}},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from torch.optim import AdamW\n","from torch.utils.data import DataLoader\n","#from transformers import AutoTokenizer, AutoModelForCausalLM\n","from lime.lime_text import LimeTextExplainer\n","from datasets import load_dataset\n","import numpy as np\n","import pandas as pd\n","from sklearn.metrics import accuracy_score, f1_score\n","import warnings\n","import tqdm as tqdm\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from transformers import RobertaTokenizer, RobertaModel, RobertaConfig\n","from captum.attr import IntegratedGradients\n","from sklearn.metrics import accuracy_score, f1_score\n","from tqdm import tqdm\n","warnings.filterwarnings(\"ignore\")\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3882,"status":"ok","timestamp":1746008413160,"user":{"displayName":"Deedahwar Mazhar","userId":"00396218496300543878"},"user_tz":-60},"id":"0MT1MYY7wp5t"},"outputs":[],"source":["dataset = load_dataset(\"hatexplain\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1746008413181,"user":{"displayName":"Deedahwar Mazhar","userId":"00396218496300543878"},"user_tz":-60},"id":"BMvCRaS6wwJ2","outputId":"a55a6921-66a3-491c-c4f6-a6e1271abebe"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'id': '23107796_gab',\n"," 'annotators': {'label': [0, 2, 2],\n","  'annotator_id': [203, 204, 233],\n","  'target': [['Hindu', 'Islam'],\n","   ['Hindu', 'Islam'],\n","   ['Hindu', 'Islam', 'Other']]},\n"," 'rationales': [[0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   1,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   1,\n","   1,\n","   1,\n","   1,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0],\n","  [0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   1,\n","   0,\n","   1,\n","   1,\n","   0,\n","   1,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   1,\n","   1,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0,\n","   0]],\n"," 'post_tokens': ['u',\n","  'really',\n","  'think',\n","  'i',\n","  'would',\n","  'not',\n","  'have',\n","  'been',\n","  'raped',\n","  'by',\n","  'feral',\n","  'hindu',\n","  'or',\n","  'muslim',\n","  'back',\n","  'in',\n","  'india',\n","  'or',\n","  'bangladesh',\n","  'and',\n","  'a',\n","  'neo',\n","  'nazi',\n","  'would',\n","  'rape',\n","  'me',\n","  'as',\n","  'well',\n","  'just',\n","  'to',\n","  'see',\n","  'me',\n","  'cry']}"]},"metadata":{},"execution_count":4}],"source":["dataset['train'][0]"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1746008413192,"user":{"displayName":"Deedahwar Mazhar","userId":"00396218496300543878"},"user_tz":-60},"id":"kJS6edbsxKI6","outputId":"b78ce772-9aa1-4b52-d322-1804ff64810d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'u really think i would not have been raped by feral hindu or muslim back in india or bangladesh and a neo nazi would rape me as well just to see me cry'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}],"source":["def join_tokens(example):\n","    example[\"text\"] = \" \".join(example[\"post_tokens\"])\n","    return example\n","\n","dataset = dataset.map(join_tokens)\n","\n","dataset[\"train\"][0][\"text\"]"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1746008413216,"user":{"displayName":"Deedahwar Mazhar","userId":"00396218496300543878"},"user_tz":-60},"id":"3yL37r-tyGnD"},"outputs":[],"source":["def combine_rationale_masks(rationale_masks, method='weighted'):\n","    \"\"\"\n","    Combines multiple binary rationale masks into a single mask.\n","    \"\"\"\n","    rationale_array = np.array(rationale_masks)\n","\n","    # Union method: If any annotator highlights a token, it is part of the rationale\n","    if method == 'union':\n","        final_rationale_mask = (rationale_array.sum(axis=0) > 0).astype(int)\n","\n","    # Majority method: A token is part of the rationale if the majority of annotators highlight it\n","    elif method == 'majority':\n","        final_rationale_mask = (rationale_array.sum(axis=0) >= (len(rationale_masks) / 2)).astype(int)\n","\n","    # Weighted method: Tokens are weighted based on how many annotators highlight it\n","    elif method == 'weighted':\n","        # Compute the average weight for each token (0-1 scale)\n","        weights = rationale_array.mean(axis=0)\n","        # Map average values to 0 or 1, with values < 1 being fractional\n","        final_rationale_mask = weights.tolist()\n","\n","    else:\n","        raise ValueError(\"Unknown method. Choose from 'union', 'majority', or 'weighted'.\")\n","\n","    return final_rationale_mask\n","\n","def safe_add_final_rationale(example):\n","    rationales = example.get('rationales', None)\n","\n","    if not rationales or not isinstance(rationales, list) or not all(isinstance(r, list) for r in rationales):\n","        # Default to a zero mask if invalid or missing\n","        num_tokens = len(example.get('post_tokens', []))\n","        example['final_rationale_mask'] = [0] * num_tokens\n","        return example\n","\n","    try:\n","        example['final_rationale_mask'] = combine_rationale_masks(rationales, method='weighted')\n","    except Exception as e:\n","        # Handle edge cases or shape mismatch\n","        num_tokens = len(example.get('post_tokens', []))\n","        example['final_rationale_mask'] = [0] * num_tokens\n","\n","    return example\n","\n","dataset = dataset.map(safe_add_final_rationale)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52,"status":"ok","timestamp":1746008413270,"user":{"displayName":"Deedahwar Mazhar","userId":"00396218496300543878"},"user_tz":-60},"id":"zOVhH0JvyLK_","outputId":"1b3a7592-f0cd-4ad2-c8ca-5c0309836cbf"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'id': '1177990839177490432_twitter',\n"," 'annotators': {'label': [0, 0, 0],\n","  'annotator_id': [6, 25, 10],\n","  'target': [['African'],\n","   ['Disability', 'African', 'Homosexual'],\n","   ['Women', 'Disability', 'African', 'Homosexual']]},\n"," 'rationales': [[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n","  [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n","  [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]],\n"," 'post_tokens': ['nigger',\n","  'faggot',\n","  'retard',\n","  'beaner',\n","  'dishwasher',\n","  'time',\n","  'to',\n","  'see',\n","  'if',\n","  'i',\n","  'get',\n","  'ban'],\n"," 'text': 'nigger faggot retard beaner dishwasher time to see if i get ban',\n"," 'final_rationale_mask': [1.0,\n","  1.0,\n","  1.0,\n","  1.0,\n","  0.3333333333333333,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0]}"]},"metadata":{},"execution_count":7}],"source":["dataset['train'][17]"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1746008413284,"user":{"displayName":"Deedahwar Mazhar","userId":"00396218496300543878"},"user_tz":-60},"id":"2cIShdB1i89q"},"outputs":[],"source":["from collections import Counter\n","\n","def resolve_hate_label(label_list):\n","    \"\"\"\n","    Convert multi-class label (0: hate, 1: neither, 2: offensive) to binary label.\n","    Returns 'hate' if majority is 0 or 2; otherwise 'non-hate'.\n","    \"\"\"\n","    if not label_list or len(label_list) != 3:\n","        return \"non-detrimental\"  # fallback\n","    counts = Counter(label_list)\n","    majority_label = counts.most_common(1)[0][0]\n","    return \"detrimenal_content\" if majority_label in [0, 2] else \"non-detrimental\"\n","def add_binary_label(example):\n","    example['binary_label'] = resolve_hate_label(example['annotators']['label'])\n","    return example\n","\n","dataset = dataset.map(add_binary_label)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1746008413294,"user":{"displayName":"Deedahwar Mazhar","userId":"00396218496300543878"},"user_tz":-60},"id":"F9LYhOVFjeuc","outputId":"0067cfff-ea6e-4455-eeec-a36d1ad62b72"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'id': '1177990839177490432_twitter',\n"," 'annotators': {'label': [0, 0, 0],\n","  'annotator_id': [6, 25, 10],\n","  'target': [['African'],\n","   ['Disability', 'African', 'Homosexual'],\n","   ['Women', 'Disability', 'African', 'Homosexual']]},\n"," 'rationales': [[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n","  [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n","  [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]],\n"," 'post_tokens': ['nigger',\n","  'faggot',\n","  'retard',\n","  'beaner',\n","  'dishwasher',\n","  'time',\n","  'to',\n","  'see',\n","  'if',\n","  'i',\n","  'get',\n","  'ban'],\n"," 'text': 'nigger faggot retard beaner dishwasher time to see if i get ban',\n"," 'final_rationale_mask': [1.0,\n","  1.0,\n","  1.0,\n","  1.0,\n","  0.3333333333333333,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0],\n"," 'binary_label': 'detrimenal_content'}"]},"metadata":{},"execution_count":9}],"source":["dataset['train'][17]"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"bte2qomrGltY","executionInfo":{"status":"ok","timestamp":1746008413311,"user_tz":-60,"elapsed":16,"user":{"displayName":"Deedahwar Mazhar","userId":"00396218496300543878"}}},"outputs":[],"source":["from torch.utils.data import Dataset\n","\n","class HateXplainDataset(Dataset):\n","    def __init__(self, dataset, tokenizer, max_length=128):\n","        \"\"\"\n","        dataset: HuggingFace-style Dataset object (already mapped with final_rationale_mask)\n","        tokenizer: Tokenizer (e.g., from transformers) to tokenize 'text'\n","        max_length: Max token length for model inputs\n","        \"\"\"\n","        self.dataset = dataset\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","        self.label_map = {\"non_detrimenal\": 0, \"detrimental\": 1}  # adjust if needed\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, idx):\n","        item = self.dataset[idx]\n","\n","        # Tokenize text\n","        encoding = self.tokenizer(\n","            item['text'],\n","            truncation=True,\n","            padding='max_length',\n","            max_length=self.max_length,\n","            return_tensors='pt'\n","        )\n","\n","        # Convert label to binary\n","        label = 1 if item['binary_label'] == 'detrimenal_content' else 0\n","\n","        # Final rationale mask (assumes already aligned with post_tokens)\n","        rationale = item.get('final_rationale_mask', [])\n","\n","        # Pad rationale to max_length\n","        rationale_tensor = torch.zeros(self.max_length)\n","        rationale_values = rationale[:self.max_length]\n","        rationale_tensor[:len(rationale_values)] = torch.tensor(rationale_values, dtype=torch.float32)\n","\n","        return {\n","            'input_ids': encoding['input_ids'].squeeze(0),  # [max_length]\n","            'attention_mask': encoding['attention_mask'].squeeze(0),\n","            'label': torch.tensor(label, dtype=torch.float32),\n","            'rationale_mask': rationale_tensor\n","        }"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"mmltoQVlHbtC","executionInfo":{"status":"ok","timestamp":1746008413329,"user_tz":-60,"elapsed":16,"user":{"displayName":"Deedahwar Mazhar","userId":"00396218496300543878"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from transformers import RobertaModel, RobertaConfig\n","\n","class CustomRobertaClassifier(nn.Module):\n","    def __init__(self, pretrained_model_name, hidden_size=128, dropout_rate=0.3):\n","        super(CustomRobertaClassifier, self).__init__()\n","\n","        self.roberta = RobertaModel.from_pretrained(pretrained_model_name)\n","        self.dropout = nn.Dropout(dropout_rate)\n","\n","        # Intermediate dense layer\n","        self.dense = nn.Linear(self.roberta.config.hidden_size, hidden_size)\n","        self.relu = nn.ReLU()\n","\n","        # Final classification layer (outputting 1 value for binary classification)\n","        self.classifier = nn.Linear(hidden_size, 1)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n","        pooled_output = outputs.pooler_output  # [batch_size, hidden_size]\n","\n","        x = self.dropout(pooled_output)\n","        x = self.relu(self.dense(x))\n","        x = self.dropout(x)\n","        logits = self.classifier(x)\n","\n","        return self.sigmoid(logits)\n","\n","\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1131,"status":"ok","timestamp":1746008414461,"user":{"displayName":"Deedahwar Mazhar","userId":"00396218496300543878"},"user_tz":-60},"id":"b8oxwFSa3xjF","outputId":"e4cdf489-4bfa-4f30-c6ec-a1df7b4e1bb2"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["\n","\n","# Load the tokenizer\n","tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n","\n","\n","model = CustomRobertaClassifier(pretrained_model_name='roberta-base')"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"9dPnXWRsJluD","executionInfo":{"status":"ok","timestamp":1746008414478,"user_tz":-60,"elapsed":4,"user":{"displayName":"Deedahwar Mazhar","userId":"00396218496300543878"}}},"outputs":[],"source":["train_dataset = HateXplainDataset(dataset['train'], tokenizer)\n","validation_dataset = HateXplainDataset(dataset['validation'], tokenizer)\n","test_dataset = HateXplainDataset(dataset['test'], tokenizer)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"CCGQFsdCKpbe","executionInfo":{"status":"ok","timestamp":1746008414479,"user_tz":-60,"elapsed":1,"user":{"displayName":"Deedahwar Mazhar","userId":"00396218496300543878"}}},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n","val_loader = DataLoader(validation_dataset, batch_size=8)\n","test_loader = DataLoader(test_dataset, batch_size=8)"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"7RRrxyD4P0ri","executionInfo":{"status":"ok","timestamp":1746008414481,"user_tz":-60,"elapsed":1,"user":{"displayName":"Deedahwar Mazhar","userId":"00396218496300543878"}}},"outputs":[],"source":["def evaluate(model, dataloader, device='cuda'):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['label'].to(device)\n","\n","            outputs = model(input_ids, attention_mask)\n","            preds = (outputs.squeeze() > 0.5).int()\n","\n","            all_preds.extend(preds.cpu().tolist())\n","            all_labels.extend(labels.cpu().int().tolist())\n","\n","    acc = accuracy_score(all_labels, all_preds)\n","    f1 = f1_score(all_labels, all_preds)\n","    print(f\"Validation Accuracy: {acc:.4f}, F1 Score: {f1:.4f}\")\n","    return f1"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"vkEZr7fyKqDR","executionInfo":{"status":"ok","timestamp":1746008414492,"user_tz":-60,"elapsed":5,"user":{"displayName":"Deedahwar Mazhar","userId":"00396218496300543878"}}},"outputs":[],"source":["from captum.attr import LayerIntegratedGradients\n","import math\n","from lime.lime_text import LimeTextExplainer\n","explainer = LimeTextExplainer(class_names=['0', '1'])\n","\n","def predict_proba(texts):\n","    model.eval()\n","    all_probs = []\n","    for text in texts:\n","        enc = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512).to(device)\n","        with torch.no_grad():\n","            probs = model(enc['input_ids'], enc['attention_mask'])\n","        probs = torch.cat([1 - probs, probs], dim=1)  # shape: (1, 2)\n","        all_probs.append(probs.cpu().numpy()[0])\n","    return np.array(all_probs)\n","\n","\n","    return out\n","def train(model, train_loader, val_loader, epochs=3, lr=2e-5, lambda_reg=0.5, device='cuda'):\n","    model.to(device)\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n","    criterion = nn.BCELoss()\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        total_loss = 0.0\n","        prev_val_f1 = 0.5\n","        loop =tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\")\n","        for batch in loop:\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['label'].unsqueeze(1).to(device)\n","            rationale_mask = batch['rationale_mask'].to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(input_ids, attention_mask)\n","\n","            pred_loss = criterion(outputs, labels)\n","            if math.isnan(pred_loss.item()):\n","              print('NAAAAN')\n","            # Integrated Gradients (token-level importance)\n","\n","\n","            for i in range(len(labels)):\n","                if labels[i].item() == 1:\n","                    model.zero_grad()\n","\n","                    # Get raw text from input_ids\n","                    tokens = tokenizer.convert_ids_to_tokens(input_ids[i])\n","                    raw_text = tokenizer.decode(input_ids[i], skip_special_tokens=True)\n","\n","                    # Use LIME to get token importance\n","                    explanation = explainer.explain_instance(raw_text, predict_proba, num_features=len(tokens), labels=[1], num_samples = 32)\n","                    lime_weights = dict(explanation.as_list(label=1))\n","\n","                    # Map LIME weights to token indices\n","                    input_tokens = tokenizer.tokenize(raw_text)\n","                    lime_vector = torch.zeros_like(input_ids[i], dtype=torch.float)\n","\n","                    for j, token_id in enumerate(input_ids[i]):\n","                        token = tokenizer.convert_ids_to_tokens(token_id.item())\n","                        for lime_token, score in lime_weights.items():\n","                            if lime_token in token:\n","                                lime_vector[j] = max(lime_vector[j], score)\n","\n","                    lime_vector = lime_vector.clamp(min=0)\n","                    norm_lime = lime_vector / (lime_vector.sum() + 1e-8)\n","\n","                    if rationale_mask[i].sum().item() == 0:\n","                        continue\n","\n","                    target_rationale = rationale_mask[i].float() / (rationale_mask[i].sum() + 1e-8)\n","                    target_rationale = target_rationale + 1e-8\n","\n","                    kl_div = (target_rationale * (target_rationale / (norm_lime + 1e-8)).log()).sum()\n","                    pred_loss += lambda_reg * kl_div\n","\n","\n","\n","\n","\n","\n","            pred_loss.backward()\n","            optimizer.step()\n","\n","            total_loss += pred_loss.item()\n","            loop.set_postfix(loss=pred_loss / 8)\n","        print(f\"Epoch {epoch+1} Training Loss: {total_loss / len(train_loader):.4f}\")\n","        f1 = evaluate(model, val_loader, device)\n","        if f1 > prev_val_f1:\n","          prev_val_f1 = f1\n","          torch.save(model.state_dict(), f'hatexplain_roberta_weights_LIME_{round(f1,4)}.pth')"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bQQQQJ9RP6cz","outputId":"269879ed-c872-47d8-f849-dba3eec05166","executionInfo":{"status":"ok","timestamp":1746027579311,"user_tz":-60,"elapsed":19164798,"user":{"displayName":"Deedahwar Mazhar","userId":"00396218496300543878"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["LAMBDA:  5\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 1 Training: 100%|██████████| 1923/1923 [53:20<00:00,  1.66s/it, loss=tensor(6.0824, device='cuda:0', grad_fn=<DivBackward0>)]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 Training Loss: 208.3325\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|██████████| 241/241 [00:13<00:00, 18.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 0.7643, F1 Score: 0.8105\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 Training: 100%|██████████| 1923/1923 [52:55<00:00,  1.65s/it, loss=tensor(25.5763, device='cuda:0', grad_fn=<DivBackward0>)]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 Training Loss: 203.3715\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|██████████| 241/241 [00:13<00:00, 18.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 0.7836, F1 Score: 0.8259\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 Training: 100%|██████████| 1923/1923 [52:46<00:00,  1.65s/it, loss=tensor(25.6723, device='cuda:0', grad_fn=<DivBackward0>)]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 Training Loss: 205.1017\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|██████████| 241/241 [00:13<00:00, 18.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 0.7711, F1 Score: 0.8020\n","LAMBDA:  10\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 1 Training: 100%|██████████| 1923/1923 [53:07<00:00,  1.66s/it, loss=tensor(46.3849, device='cuda:0', grad_fn=<DivBackward0>)]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 Training Loss: 403.7306\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|██████████| 241/241 [00:13<00:00, 18.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 0.7700, F1 Score: 0.7923\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 Training: 100%|██████████| 1923/1923 [53:08<00:00,  1.66s/it, loss=tensor(62.6342, device='cuda:0', grad_fn=<DivBackward0>)]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 Training Loss: 406.9772\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|██████████| 241/241 [00:13<00:00, 18.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 0.7882, F1 Score: 0.8195\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 Training: 100%|██████████| 1923/1923 [52:40<00:00,  1.64s/it, loss=tensor(32.6552, device='cuda:0', grad_fn=<DivBackward0>)]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 Training Loss: 407.7020\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|██████████| 241/241 [00:13<00:00, 18.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 0.7794, F1 Score: 0.8132\n"]}],"source":["lambs = [5, 10]\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","for lamb in lambs:\n","  print('LAMBDA: ',lamb)\n","  model = CustomRobertaClassifier(pretrained_model_name='roberta-base')\n","  model.to(device)\n","  train(model, train_loader, val_loader, epochs=3, lr=2e-5, lambda_reg=lamb)\n"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"_xuK09NoOSU_","executionInfo":{"status":"ok","timestamp":1746027580061,"user_tz":-60,"elapsed":747,"user":{"displayName":"Deedahwar Mazhar","userId":"00396218496300543878"}}},"outputs":[],"source":["torch.save(model.state_dict(), 'hatexplain_roberta_weights_LIME.pth')"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9XZrNm6qB4xA","outputId":"cf8adaca-6255-4ae3-e7fc-3b875be7d52c","executionInfo":{"status":"ok","timestamp":1746027855006,"user_tz":-60,"elapsed":274943,"user":{"displayName":"Deedahwar Mazhar","userId":"00396218496300543878"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: .config/ (stored 0%)\n","  adding: .config/.last_update_check.json (deflated 24%)\n","  adding: .config/configurations/ (stored 0%)\n","  adding: .config/configurations/config_default (deflated 15%)\n","  adding: .config/logs/ (stored 0%)\n","  adding: .config/logs/2025.04.28/ (stored 0%)\n","  adding: .config/logs/2025.04.28/13.34.26.846099.log (deflated 58%)\n","  adding: .config/logs/2025.04.28/13.33.57.096159.log (deflated 92%)\n","  adding: .config/logs/2025.04.28/13.34.35.168196.log (deflated 86%)\n","  adding: .config/logs/2025.04.28/13.34.50.274199.log (deflated 56%)\n","  adding: .config/logs/2025.04.28/13.34.41.209709.log (deflated 58%)\n","  adding: .config/logs/2025.04.28/13.34.49.603666.log (deflated 57%)\n","  adding: .config/default_configs.db (deflated 98%)\n","  adding: .config/gce (stored 0%)\n","  adding: .config/.last_opt_in_prompt.yaml (stored 0%)\n","  adding: .config/hidden_gcloud_config_universe_descriptor_data_cache_configs.db (deflated 97%)\n","  adding: .config/config_sentinel (stored 0%)\n","  adding: .config/active_config (stored 0%)\n","  adding: .config/.last_survey_prompt.yaml (stored 0%)\n","  adding: hatexplain_roberta_weights_LIME_0.8259.pth (deflated 12%)\n","  adding: hatexplain_roberta_weights_LIME_0.8195.pth (deflated 12%)\n","  adding: hatexplain_roberta_weights_LIME_0.802.pth (deflated 12%)\n","  adding: hatexplain_roberta_weights_LIME_0.7923.pth (deflated 12%)\n","  adding: hatexplain_roberta_weights_LIME.pth (deflated 12%)\n","  adding: hatexplain_roberta_weights_LIME_0.8105.pth (deflated 12%)\n","  adding: hatexplain_roberta_weights_LIME_0.8132.pth (deflated 12%)\n","  adding: sample_data/ (stored 0%)\n","  adding: sample_data/anscombe.json (deflated 83%)\n","  adding: sample_data/README.md (deflated 39%)\n","  adding: sample_data/california_housing_test.csv (deflated 76%)\n","  adding: sample_data/mnist_test.csv (deflated 88%)\n","  adding: sample_data/california_housing_train.csv (deflated 79%)\n","  adding: sample_data/mnist_train_small.csv (deflated 88%)\n"]}],"source":["!zip -r files_LIME.zip . -x \"*.ipynb_checkpoints*\""]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":280},"id":"5ipil2UWB-AF","outputId":"edc2a360-c5eb-4013-a216-011ec7e1bcf2","executionInfo":{"status":"error","timestamp":1746027855183,"user_tz":-60,"elapsed":172,"user":{"displayName":"Deedahwar Mazhar","userId":"00396218496300543878"}}},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"Cannot find file: files.zip","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-64060beb8cc0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"files.zip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    231\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cannot find file: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: files.zip"]}],"source":["from google.colab import files\n","files.download(\"files.zip\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[{"file_id":"1aguE7BewrmEpoU0QYomu7OpHbGyyreK-","timestamp":1746006464121}],"authorship_tag":"ABX9TyOV0RDOC2tqOu9Uxe53Mkta"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}